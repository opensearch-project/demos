import dotenv
from os import getenv
from opensearchpy import OpenSearch
from opensearch_py_ml.ml_commons import MLCommonClient
from copy import deepcopy

if (not dotenv.load_dotenv()):
  print("No .env file found. Loading defaults...")

ADMIN_PW = 'admin' if getenv('ADMIN_PW') == None else getenv('ADMIN_PW')
ADMIN_UN = 'admin' if getenv('ADMIN_UN') == None else getenv('ADMIN_UN')
HOSTS = 'localhost:9200' if getenv('HOSTS') == None else getenv('HOSTS')
DEVELOPMENT = True if getenv('DEVELOPMENT') == None else getenv('DEVELOPMENT')

##### Monkey patching ðŸ¤ª #####

from opensearch_py_ml.ml_commons.ml_common_utils import (
  ML_BASE_URI,
  TIMEOUT,
)
from typing import Union, Any
from datetime import time
from opensearchpy.client.utils import SKIP_IN_PATH, _make_path


class MLClient(MLCommonClient):
  def register_model_group(self, model_group_meta_json: dict) -> str:
    """
    This method registers a model group with ML Commons' register api

    :param model_group_meta_json: a dictionary object with model group configurations
    :type model_group_meta_json: dict
    :return: returns a unique id of the model group
    :rtype: string
    """

    output: dict = self._client.transport.perform_request(
      method="POST",
      url=f"{ML_BASE_URI}/model_groups/_register",
      body=model_group_meta_json,
    )
    if not output["status"] == "CREATED":
      raise Exception("Failed to create model group")

    return output["model_group_id"]

  def get_model_group_id(self, model_group_name: str = None) -> str | None:
    """
    This gets a model group id by doing a search on the model name

    :param model_group_name: the model group name
    :type model_group_name: str
    :return: returns a unique id of the model group or none if it doesnt exist
    :rtype: string | None
    """
    query = {"query": {"match": {}}}

    if model_group_name is not None:
      query["query"]["match"].update({"name": model_group_name})
    else:
      raise Exception("Model group name and id cannot both be empty")
    output = self._client.transport.perform_request(
      method="POST",
      url=f"{ML_BASE_URI}/model_groups/_search",
      body=query,
    )

    if not output["hits"]["total"]["value"] > 0:
      return None

    return output["hits"]["hits"][0]["_id"]

  def create_connector(self, connector_meta_json: dict) -> str:
    """
    This method creates a ML Connector using ML Commons' create api

    :param connector_meta_json: a dictionary object with model configurations
    :type connector_meta_json: dict
    :return: returns a unique id of the connector
    :rtype: string
    """
    output: dict = self._client.transport.perform_request(
      method="POST",
      url=f"{ML_BASE_URI}/connectors/_create",
      body=connector_meta_json,
    )
    if not output["status"] == "CREATED":
      raise Exception("Failed to create connector")

    return output["connector_id"]

  def get_connector_id(self, connector_name: str = None) -> str | None:
    """
    This gets a connector id by doing a search on the connector name

    :param connector_name: the connector name
    :type connector_name: string
    :return: returns a unique id of the connector or none if it doesnt exist
    :rtype: string | None
    """
    query = {"query": {"match": {}}}

    if connector_name is not None:
      query["query"]["match"].update({"name": connector_name})
    else:
      raise Exception("Model group name and id cannot both be empty")

    try:
      output = self._client.transport.perform_request(
        method="POST",
        url=f"{ML_BASE_URI}/connectors/_search",
        body=query,
      )
    except Exception as e:

      # if not output["hits"]["total"]["value"] > 0:
      return None

    return output["hits"]["hits"][0]["_id"]

  def register_connector_model(self, model_meta_json: dict) -> str:
    """
        This method creates a model using an already existing connector

        :param model_meta_json: a dictionary object with model configurations
        :type model_meta_json: dict
        :return: returns a unique id of the model
        :rtype: string
        """
    output: Union[bool, Any] = self._client.transport.perform_request(
      method="POST",
      url=f"{ML_BASE_URI}/models/_register?deploy=true",
      body=model_meta_json,
    )
    end = time.time() + TIMEOUT  # timeout seconds
    task_flag = False
    while not task_flag and time.time() < end:
      time.sleep(1)
      status = self._get_task_info(output["task_id"])
      if status["state"] != "CREATED":
        task_flag = True
    # TODO: need to add the test case later for this line
    if not task_flag:
      raise TimeoutError("Model registration timed out")
    if status["state"] == "FAILED":
      raise Exception(status["error"])
    print("Model was registered successfully. Model Id: ", status["model_id"])
    return status["model_id"]

  def delete_model_group(self, model_group_id: dict) -> dict:
    """
    This method sends the pretrained model info to ML Commons' register api

    :param model_meta_json: a dictionary object with model configurations
    :type model_meta_json: dict
    :return: returns a unique id of the model
    :rtype: string
    """
    return self._client.transport.perform_request(
      method="DELETE",
      url=f"{ML_BASE_URI}/model_groups/{model_group_id}",
    )

  def delete_connector(self, connector_id: str) -> dict:
    """
      This method deletes a connector from opensearch cluster (using ml commons api)

      :param connector_id: unique id of the connector
      :type connector_id: string
      :return: returns a json object, with detailed information about the deleted connector
      :rtype: object
      """

    API_URL = f"{ML_BASE_URI}/connectors/{connector_id}"

    return self._client.transport.perform_request(
      method="DELETE",
      url=API_URL,
    )

  def put_conversation(self, body: dict) -> dict:
    """
    Creates new conversation for Cohere
    :param body: body of search pipeline request (should be name: "some_name")
    :type body: dict
    :return: returns json object if request was successful
    :rtype: object
    """
    for param in (id, body):
      if param in SKIP_IN_PATH:
        raise ValueError("Empty value passed for a required argument.")

    return self._client.transport.perform_request(method="POST",
                                                  url=_make_path("_plugins", "_ml", "memory",
                                                                 "conversation"),
                                                  body=body)

  def get_search_pipeline(self, id=None) -> dict:
    """
      Returns search pipeline if it exists

      :param id: Id of pipeline to be retrieved
      :type id: string
      :return: returns json object, if pipeline exists
      :rtype: object
      """
    return self._client.transport.perform_request(method="GET",
                                                  url=_make_path("_search", "pipeline", id))

  def put_search_pipeline(self, id: str, body: dict) -> dict:
    """
      Creates or updates search pipeline

      :param id: Pipeline id
      :type id: string
      :param body: body of search pipeline request
      :type body: dict
      :return: returns json object if request was successful
      :rtype: object
      """
    for param in (id, body):
      if param in SKIP_IN_PATH:
        raise ValueError("Empty value passed for a required argument.")

    return self._client.transport.perform_request(method="PUT",
                                                  url=_make_path("_search", "pipeline", id),
                                                  body=body)

  def delete_search_pipeline(self, id: str) -> None:
    """
      Deletes search pipeline

      :param id: Pipeline id
      :type id: string
      :return: returns json object if request was successful
      :rtype: object
      """
    return self._client.transport.perform_request(method="DELETE",
                                                  url=_make_path("_search", "pipeline", id))


##### END MONKEYPATCH #####


def opensearch_connection_builder(use_ssl=True) -> MLClient:
  config = {
    "hosts": HOSTS,
    "http_auth": (ADMIN_UN, ADMIN_PW),
    "use_ssl": use_ssl,
    "verify_certs": True
  }

  if DEVELOPMENT:
    config['verify_certs'] = False

  return MLClient(OpenSearch(**config))


# Handles the case for when dictionary values are lists
def opensearch_compare_dictionaries(value1, value2):
  if type(value1) != type(value2):
    return False

  if isinstance(value1, (int, float, str, bool)):
    return value1 is value2 if isinstance(value1, bool) else value1 == value2

  if isinstance(value1, list):
    if len(value1) != len(value2):
      return False
    for item1, item2 in zip(value1, value2):
      if not opensearch_compare_dictionaries(item1, item2):
        return False
    return True

  if isinstance(value1, dict):
    if set(value1.keys()) != set(value2.keys()):
      return False
    for key in value1:
      if not opensearch_compare_dictionaries(value1[key], value2[key]):
        return False
    return True

  return False


def shorten_json_file_same_index(json_file, num_words=150, overlap=0.3) -> list:
  """
  Args:
    json_file: a json index with OpenSearch document to be ingested
    num_words: content length of each sub-document
    overlap: The percentage amount of overlap in breaking the documents
  Returns:
    A list of dict with same metadata but content is a chunk of sub-document if successful, raise exception if failed
  """
  if not isinstance(json_file, dict) or 'content' not in json_file:
    raise ValueError(
      "Inappropriate Argument json_file must be a valid dict of OpenSearch json index")

  if num_words <= 0:
    raise ValueError("Inappropriate Argument: num_words must be positive")

  if overlap <= 0 or overlap >= 1:
    raise ValueError("Inappropriate Argument: overlap must be within 0 and 1")

  sentence_to_split = json_file['content'].split()
  temp = None
  result = []

  while len(sentence_to_split) > (num_words):
    overlapped_bound = int(num_words - (num_words * overlap))
    temp = deepcopy(json_file)
    temp['content'] = " ".join(sentence_to_split[:num_words])
    result.append(temp)
    sentence_to_split = sentence_to_split[overlapped_bound:]

  temp = deepcopy(json_file)
  temp['content'] = " ".join(sentence_to_split)
  result.append(temp)

  return result


def model_exists(client: MLClient, model_name: str) -> bool:
  """
    Args:
        client (MLClient): The OpenSearch ML client.
        model_name (str): The name of the model to check.
    Returns:
        returns Model ID if model exists else None
    """
  existing_models = client.search_model({"query": {"match": {"name": model_name}}})
  if existing_models["hits"]["total"]["value"] > 0:
    return existing_models["hits"]["hits"][0]["_id"]
  return None
